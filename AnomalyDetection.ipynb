{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies in the real world\n",
    "\n",
    "Allow me to quote the following from classic book **Data Mining. Concepts and Techniques by Han et al.** -\n",
    "\n",
    "Outlier detection (also known as anomaly detection) is the process of finding data objects with behaviors that are very different from expectation. Such objects are called outliers or anomalies\n",
    "\n",
    "Suppose, you are a credit card holder and on an unfortunate day it got stolen. Payment Processor Companies (like PayPal) do keep a track of your usage pattern so as to notify in case of any dramatic change in the usage pattern. The patterns include transaction amounts, the location of transactions and so on. If a credit card is stolen, it is very likely that the transactions may vary largely from the usual ones. This is where (among many other instances) the companies use the concepts of anomalies to detect the unusual transactions that may take place after the credit card theft. But don’t let that confuse anomalies with noise. **Noise and anomalies are not the same**. So, how noise looks like in the real world?\n",
    "\n",
    "Let’s take the example of the sales record of a grocery shop. People tend to buy a lot of groceries at the start of a month and as the month progresses the grocery shop owner starts to see a vivid decrease in the sales. Then he starts to give discounts on a number of grocery items and also does not fail to advertise about the scheme. This discount scheme might cause an uneven increase in sales but are they normal? They, sure, are not. These are **noises** (more specifically stochastic noises).\n",
    "\n",
    "Could not get any better, right? To be able to make more sense of anomalies, it is important to understand what makes an anomaly different from noise.\n",
    "\n",
    "The way data is generated has a huge role to play in this. For the normal instances of a dataset, it is more likely that they were generated from the same process but in case of the outliers, it is often the case that they were generated from a different process(s).\n",
    "\n",
    "<img src=\"images/anomaly_detection_1.PNG\">\n",
    "\n",
    "In the above figure, I show you what it is like to be outliers within a set of *closely related data-points*. The closeness is governed by the process that generated the data points. From this, it can be inferred that the process for generated those two encircled data-points must have been different from that one that generated the other ones. ut how do we justify that those red data points were generated by some other process? ***Assumptions!***\n",
    "\n",
    "While doing anomaly analysis, it is a common practice to make several assumptions on the normal instances of the data and then distinguish the ones that violate these assumptions. More on these assumptions later!\n",
    "\n",
    "The above figure may give you a notion that **anomaly analysis** and **cluster analysis** may be the same things. They are very closely related indeed, but they are not the same! They vary in terms of their purposes. **While cluster analysis** lets you **group similar data points**, **anomaly analysis** lets you **figure out the odd ones among a set of data points.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of anomalies in data\n",
    "\n",
    "The way anomalies are generated hugely varies from domain to domain, application to application. Let’s take a moment to review some of the fields where anomaly detection is extremely vital -\n",
    "\n",
    "* **Intrusion detection systems**: In the field of computer science, unusual network traffic, abnormal user actions are common forms of intrusions. These intrusions are capable enough to breach many confidential aspects of an organization. Detection of these intrusions is a form of anomaly detection.\n",
    "\n",
    "* **Fraud detection in transactions** - One of the most prominent use cases of anomaly detection. Nowadays, it is common to hear about events where one’s credit card number and related information get compromised. This can, in turn, lead to abnormal behavior in the usage pattern of the credit cards. Therefore, to effectively detect these frauds, anomaly detection techniques are employed.\n",
    "\n",
    "* **Electronic sensor events** - Electronic sensors enable us to capture data from various sources. Nowadays, our mobile devices are also powered with various sensors like light sensors, accelerometer, proximity sensors, ultrasonic sensors and so on. Sensor data analysis has a lot of interesting applications. But what happens when the sensors become ineffective? This shows up in the data they capture. When a sensor becomes dysfunctional, it fails to capture the data in the correct way and thereby produces anomalies.  For example, one’s pulse rate may get abnormally high due to several conditions and this leads to anomalies. This point is also very crucial considering today’s industrial scenario. We are approaching and embracing **Industry 4.0** in which **IoT** (Internet of Things) and **AI** (Artificial Intelligence) are integral parts. When these sensors start to behave inconsistently the signals they convey get also uncanny, thereby causing unprecedented troubleshooting. Hence, systematic anomaly detection is a must here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies can be of different types\n",
    "\n",
    "In the data science literature, anomalies can be of the three types as follows. Understanding these types can significantly affect the way of dealing with anomalies.\n",
    "\n",
    "* Global\n",
    "* Contextual\n",
    "* Collective\n",
    "\n",
    "In the following subsections, we are to take a closer look at each of the above and discuss their key aspects like their importance, grounds where they should be paid importance to.\n",
    "\n",
    "### 1. Global anomalies\n",
    "\n",
    "Global anomalies are the most common type of anomalies and correspond to those data points which deviate largely from the rest of the data points. The figure used in the “Find the odd ones out: Anomalies in data” section actually depicts global anomalies.\n",
    "\n",
    "<img src=\"images/anomaly_detection_2.PNG\">\n",
    "\n",
    "You might be thinking that the idea of global anomalies (deviation from the normal) may not always hold practical with respect to numerous conditions, context and similar aspects.  Yes, you are thinking just right. Anomalies can be contextual too!\n",
    "\n",
    "### 2. Contextual anomalies\n",
    "\n",
    "Consider today’s temperature to be 32 degrees centigrade and we are in Kolkata, a city situated in India. Is the temperature normal today? This is a highly relative question and demands for more information to be concluded with an answer. Information about the season, location etc. are needed for us to jump to give any response to the question - “Is the temperature normal today?”\n",
    "\n",
    "Now, in India, specifically in Kolkata, if it is Summer, the temperature mentioned above is fine. But if it is Winter, we need to investigate further.  Let’s take another example. We all are aware of the tremendous climate change i.e. causing the Global Warming. The latest results are with us also. From the archives of The Washington Post:\n",
    "\n",
    " - Alaska just finished one of its most unusually warm Marches ever recorded. In its northern reaches, the March warmth was unprecedented.\n",
    " \n",
    "Take note of the phrase “unusually warm”. It refers to 59-degrees Fahrenheit. But this may not be unusually warm for other countries. This unusual warmth is an anomaly here.\n",
    "\n",
    "These are called **contextual anomalies** where the deviation that leads to the anomaly **depends on contextual information**. These contexts are **governed by contextual attributes and behavioral attributes**. In this example, **location is a contextual attribute** and **temperature is a behavioral attribute.**\n",
    "\n",
    "<img src=\"images/anomaly_detection_3.PNG\">\n",
    "\n",
    "The above figure depicts a time-series data over a particular period of time. The plot was further smoothed by kernel density estimation to present the boundary of the trend. The values have not fallen outside the normal global bounds, but there are indeed abnormal points (highlighted in orange) when compared to the seasonality.\n",
    "\n",
    "### 3. Collective anomalies\n",
    "\n",
    "n the following figure, the data points marked in green have collectively formed a region which substantially deviates from the rest of the data points.\n",
    "\n",
    "<img src=\"images/anomaly_detection_4.PNG\">\n",
    "\n",
    "\n",
    "This an example of a collective anomaly. The main idea behind collective anomalies is that the data points included in forming the collection may not be anomalies when considered individually. Let’s take the example of a daily supply chain in a textile firm. Delayed shipments are very common in industries like this. But on a given day, if there are numerous shipment delays on orders then it might need further investigation. The delayed shipments do not contribute to this individually but a collective summary is taken into account when analyzing situations like this.\n",
    "\n",
    "Collective anomalies are interesting because here you do not only to look at individual data points but also analyze their behavior in a collective fashion.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning & anomalies: Could it get any better?\n",
    "\n",
    "The heart and soul of any machine learning model is the data that is being fed to it. Data can be of any form practically - structured, semi-structured and unstructured. Let’s go into these categories for now. At all their cores, machine learning models try to find the underlying patterns of the data that best represent them. These patterns are generally learned as mathematical functions and these patterns are used for making predictions, making inferences and so on. To this end, consider the following toy dataset:\n",
    "\n",
    "<img src=\"images/anomaly_detection_5.PNG\">\n",
    "\n",
    "The dataset has two features: **x1** and **x2** and the predictor variable (or the label) is **y**. The dataset has got 6 observations. Upon taking a close look at the data points, the fifth data point appears to be the odd one out here. Really? Well, it depends on a few things -\n",
    "\n",
    "* We need to take the domain into the account here. The domain to which the dataset belongs to. This is particularly important because until and unless we have information on that, we cannot really say if the fifth data point is an extreme one (anomaly). It might so happen that this set of values is possible in the domain.\n",
    "\n",
    "* While the data was getting captured, what was the state of the capturing process? Was it functioning in the way it is expected to? We may not always have answers to questions like these. But they are worth considering because this can change the whole course of the anomaly detection process.\n",
    "\n",
    "Now coming to the perspective of a machine learning model, let’s formalize the problem statement:\n",
    "\n",
    " - Given a set of input vectors x1 and x2 the task is to predict y.\n",
    " \n",
    "The prediction task is a classification task. Say, you have trained a model M on this data and you got a classification accuracy of 96% on this dataset. Great start for a baseline model, isn’t it? You may not be able to come up with a better model than this for this dataset. Is this evaluation just enough? Well, the answer is no! Let’s now find out why.\n",
    "\n",
    "When we know that our dataset consists of a weird data-point, just going by the classification accuracy is not correct. Classification accuracy refers to the percentage of the correct predictions made by the model. So, before jumping into a conclusion of the model’s predictive supremacy, we should check if the model is able to correctly classify the weird data-point. Although the importance of anomaly detection varies from application to application, still it is a good practice to take this part into account. So, long story made short, when a dataset contains anomalies, it may not always be justified to just go with the classification accuracy of a model as the evaluation criteria.\n",
    "\n",
    " * The illusion, that gets created by the classification accuracy score in situations described above, is also known as  **classification paradox.**\n",
    " \n",
    "So, when a machine learning model is learning the patterns of the data given to it, it may have a critical time figuring out these anomalies and may give unexpected results. A very trivial and naive way to tackle this is just dropping off the anomalies from the data before feeding it to a model. But what happens when in an application, detection of the anomalies (we have seen the examples of these applications in the earlier sections) is extremely important? Can’t the anomalies be utilized in a more systematic modeling process? Well, the next section deals with that.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting benefits from anomalies\n",
    "\n",
    "When training machine learning models for applications where anomaly detection is extremely important,  we need to thoroughly investigate if the models are being able to effectively and consistently identify the anomalies. A good idea of utilizing the anomalies that may be present in the data is to train a model with the anomalies themselves so that the model becomes robust to the anomaly detection. So, on a very high level, the task becomes training a machine learning model to specifically identify anomalies and later the model can be incorporated in a broader pipeline of automation.\n",
    "\n",
    "A well-known method to train a machine learning model for this purpose is **Cost-Sensitive Learning.** The idea here is to associate a certain cost whenever a model identifies an anomaly. Traditional machine learning models do not penalize or reward the wrong or correct predictions that they make. Let’s take the example of a fraudulent transaction detection system. To give you a brief description of the objective of the model - to identify the fraudulent transactions effectively and consistently. This is essentially a binary classification task. Now, let’s see what happens when a model makes a wrong prediction about a given transaction. The model can go wrong in the following cases  -\n",
    " * Either misclassify the legitimate transactions as the fraudulent ones\n",
    "or\n",
    "* Misclassify the fraudulent ones as the legitimate ones\n",
    "\n",
    "<img src=\"images/anomaly_detection_6.PNG\">\n",
    "\n",
    "To be able to understand this more clearly, we need to take the cost (that is incurred by the authorities) associated with the misclassifications into the account. If a legitimate transaction is categorized as fraudulent, the user generally contacts the bank to figure out what went wrong and in most of the cases, the respective authority and the user come to a mutual agreement. In this case, the administrative cost of handling the matter is most likely to be negligible. Now, consider the other scenario - “Misclassify the fraudulent ones as the legitimate ones.” This can indeed lead to some serious concerns. Consider, your credit card has got stolen and the thief purchased (let’s assume he somehow got to know about the security pins as well) something worth an amount (which is unusual according to your credit limit). Further, consider, this transaction did not raise any alarm to the respective credit card agency. In this case, the amount (that got debited because of the theft) may have to be reimbursed by the agency.\n",
    "\n",
    "In traditional machine learning models, the optimization process generally happens just by minimizing the cost for the wrong predictions as made by the models. So, when cost-sensitive learning is incorporated to help prevent this potential issue, we associate a hypothetical cost when a model identifies an anomaly correctly. The model then tries to minimize the net cost (as incurred by the agency in this case) instead of the misclassification cost.\n",
    "\n",
    "**(N.B.: All machine learning models try to optimize a cost function to better their performance.)\n",
    "\n",
    " * Effectiveness and consistency are very important in this regard because sometimes a model may be randomly correct in the identification of an anomaly. We need to make sure that the model performs consistently well on the identification of the anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A case study of anomaly detection in Python\n",
    "\n",
    "We will start off just by looking at the dataset from a visual perspective and see if we can find the anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Shpw the plots in your Jupyter Notebook\n",
    "%matplotlib inline\n",
    "# Use a predefined style set\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a dummy dataset for ourselves. The dataset will contain just two columns -\n",
    "\n",
    "* Name of the employees of an organization\n",
    "* Salaries of those employees (in USD) within a range of 1000 to 2500 (Monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generating the names (and make them look like the real ones) we will use a Python library called Faker (read the documentation here). For generating salaries, we will use the good old numpy. After generating these, we will merge them in a pandas DataFrame. We are going to generate records for 100 employees. Let's begin.\n",
    "\n",
    "**Note:** Synthesizing dummy datasets for experimental purposes is indeed an essential skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "\n",
    "# To ensure the results are reproducible\n",
    "fake.seed(4321)\n",
    "\n",
    "names_list = []\n",
    "\n",
    "fake = Faker()\n",
    "for _ in range(100):\n",
    "  names_list.append(fake.name())\n",
    "\n",
    "# Verify if 100 names were generated\n",
    "len(names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To ensure the results are reproducible\n",
    "np.random.seed(7)\n",
    "\n",
    "salaries = []\n",
    "for _ in range(100):\n",
    "    salary = np.random.randint(1000,2500)\n",
    "    salaries.append(salary)\n",
    "\n",
    "    # Verify if 100 salariy values were generated\n",
    "len(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Salary (in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Brown</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jacob Stein</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cody Brown</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Larry Morales</td>\n",
       "      <td>1502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jessica Hendricks</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Person  Salary (in USD)\n",
       "0        Jason Brown             1175\n",
       "1        Jacob Stein             2220\n",
       "2         Cody Brown             1537\n",
       "3      Larry Morales             1502\n",
       "4  Jessica Hendricks             1211"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create pandas DataFrame\n",
    "salary_df = pd.DataFrame(\n",
    "    {'Person': names_list,\n",
    "     'Salary (in USD)': salaries\n",
    "    })\n",
    "\n",
    "# Print a subsection of the DataFrame\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now manually change the salary entries of two individuals. In reality, this can actually happen for a number of reasons such as the data recording software may have got corrupted at the time of recording the respective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "salary_df.at[16, 'Salary (in USD)'] = 23\n",
    "salary_df.at[65, 'Salary (in USD)'] = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person             Miss Amanda Harris MD\n",
      "Salary (in USD)                       23\n",
      "Name: 16, dtype: object\n",
      "Person             Joyce Bishop\n",
      "Salary (in USD)              17\n",
      "Name: 65, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify if the salaries were changed\n",
    "print(salary_df.loc[16])\n",
    "print(salary_df.loc[65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to treat the task of anomaly detection as a classification task, we need a labeled dataset. Let's give our existing dataset some labels.\n",
    "\n",
    "We will first assign all the entries to the class of 0 and then we will manually edit the labels for those two anomalies. We will keep these class labels in a column named class. The label for the anomalies will be 1 (and for the normal entries the labels will be 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person             Miss Amanda Harris MD\n",
      "Salary (in USD)                       23\n",
      "class                                  1\n",
      "Name: 16, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First assign all the instances to \n",
    "salary_df['class'] = 0\n",
    "\n",
    "# Manually edit the labels for the anomalies\n",
    "salary_df.at[16, 'class'] = 1\n",
    "salary_df.at[65, 'class'] = 1\n",
    "\n",
    "# Veirfy \n",
    "print(salary_df.loc[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a binary classification task. We are going to use proximity-based anomaly detection for solving this task. The basic idea here is that the proximity of an anomaly data point to its nearest neighboring data points largely deviates from the proximity of the data point to most of the other data points in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the k-NN classification method for this. Also, we are going to use a Python library called PyOD which is specifically developed for anomaly detection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNN module from PyOD\n",
    "from pyod.models.knn import KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column Person is not at all useful for the model as it is nothing but a kind of identifier. Let's prepare the training data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNN(algorithm='auto', contamination=0.02, leaf_size=30, method='largest',\n",
       "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "  radius=1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segregate the salary values and the class labels \n",
    "X = salary_df['Salary (in USD)'].values.reshape(-1,1)\n",
    "y = salary_df['class'].values\n",
    "\n",
    "# Train kNN detector\n",
    "clf = KNN(contamination=0.02, n_neighbors=5)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss the two parameters we passed into KNN() -\n",
    "\n",
    "**contamination** - the amount of anomalies in the data (in percentage) which for our case is 2/100 = 0.02\n",
    "**n_neighbors** - number of neighbors to consider for measuring the proximity\n",
    "\n",
    "Let's now get the prediction labels on the training data and then get the outlier scores of the training data. The outlier scores of the training data. The higher the scores are, the more abnormal. This indicates the overall abnormality in the data. These handy features make PyOD a great utility for anomaly detection related tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction labels of the training data\n",
    "y_train_pred = clf.labels_ \n",
    "    \n",
    "# Outlier scores\n",
    "y_train_scores = clf.decision_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to evaluate KNN() with respect to the training data. PyOD provides a handy function for this - evaluate_print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN ROC:1.0, precision @ rank n:1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the utility function for model evaluation\n",
    "from pyod.utils import evaluate_print\n",
    "\n",
    "# Evaluate on the training data\n",
    "evaluate_print('KNN', y, y_train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the KNN() model was able to perform exceptionally good on the training data. It provides three metrics and their scores -\n",
    "\n",
    "* ROC\n",
    "* Precision along with a confidence rank\n",
    "\n",
    "Note: While detecting anomalies, we almost always consider ROC and Precision as it gives a much better idea about the model's performance. We have also seen its significance in the earlier sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any test data. But we can generate a sample salary value, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A salary of $37 (an anomaly right?)\n",
    "X_test = np.array([[37.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test how if the model could detect this salary value as an anomaly or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what the model predicts on the given test data point\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model predicts just right. Let's also see how the model does on a normal data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A salary of $1256\n",
    "X_test_abnormal = np.array([[1256.]])\n",
    "\n",
    "# Predict\n",
    "clf.predict(X_test_abnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted this one as the normal data point which is correct. With this, we conclude our case study of anomaly detection which leads us to the concluding section of this article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref : https://blog.floydhub.com/introduction-to-anomaly-detection-in-python/\n",
    "https://github.com/sayakpaul/FloydHub-Anomaly-Detection-Blog/blob/master/FloydHub%20Anomaly%20Detection%20Blog.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
